{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd8339fc-ccd8-4fcd-9247-b4e85c321551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0faeff4-ef7e-41f6-a923-bb570898f3cc",
   "metadata": {},
   "source": [
    "## Attention encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aa7aaac-de08-4d87-b08d-297f244a7ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_size, heads): \n",
    "        super(SelfAttention, self).__init__() \n",
    "        self.embed_size = embed_size \n",
    "        self.heads = heads\n",
    "        self.head_dim = embed_size // heads\n",
    "        \n",
    "        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False) \n",
    "        self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False) \n",
    "        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False) \n",
    "        self.fc_out = nn.Linear(heads*self.head_dim, embed_size)\n",
    "\n",
    "    def forward(self, values, keys, query, mask):\n",
    "        N = query.shape[0]\n",
    "        value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1]\n",
    "        \n",
    "        # Split embedding into self.heads pieces\n",
    "        values = values.reshape(N, value_len, self.heads, self.head_dim)\n",
    "        keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n",
    "        queries = query.reshape(N, query_len, self.heads, self.head_dim)\n",
    "\n",
    "        values = self.values(values) \n",
    "        keys = self.keys(keys)\n",
    "        queries = self.queries(queries)\n",
    "        \n",
    "        QK = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys]) \n",
    "        \n",
    "        if mask is not None:\n",
    "            QK = QK.masked_fill(mask == 0, float(\"-1e20\"))\n",
    "        \n",
    "        attention = torch.softmax(QK / (self.embed_size**(1/2)), dim=3)\n",
    "        out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(N, query_len, self.heads*self.head_dim)\n",
    "        out = self.fc_out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90d57413-2a6a-4585-bf2e-19d11384b03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, dropout, forward_expansion): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.attention = SelfAttention(embed_size, heads)\n",
    "        self.norm1 = nn.LayerNorm(embed_size) \n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_size, forward_expansion*embed_size), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(forward_expansion*embed_size, embed_size)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "      \n",
    "    def forward(self, value, key, query, mask): \n",
    "        attention = self.attention(value, key, query, mask)\n",
    "        \n",
    "        x = self.dropout(self.norm1(attention + query)) \n",
    "        forward = self.feed_forward(x)\n",
    "        out = self.dropout(self.norm2(forward + x)) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6988ae55-08dd-40db-9d90-5f0ed7fbb5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module): \n",
    "    def __init__(\n",
    "        self,\n",
    "        src_vocab_size,\n",
    "        embed_size,\n",
    "        num_layers,\n",
    "        heads,\n",
    "        device,\n",
    "        forward_expansion,\n",
    "        dropout,\n",
    "        max_length\n",
    "    ):\n",
    "        super(Encoder, self).__init__() \n",
    "        self.embed_size = embed_size\n",
    "        self.device = device\n",
    "        self.word_embedding = nn.Embedding(src_vocab_size, embed_size) \n",
    "        self.position_embedding = nn.Embedding(max_length, embed_size)\n",
    "    \n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerBlock(embed_size, heads, dropout=dropout, forward_expansion=forward_expansion) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        N, seq_length = x.shape\n",
    "        positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)\n",
    "        out = self.dropout(self.word_embedding(x) + self.position_embedding(positions))\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            out = layer(out, out, out, mask)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a043c7e-779f-492c-8fbb-76a7d71cdb1a",
   "metadata": {},
   "source": [
    "## sLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35de0db0-bad1-4fda-a9b5-cda6db0881a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "From Mudit Bhargava\n",
    "\"\"\"\n",
    "class sLSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(sLSTMCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.weight_ih = nn.Parameter(torch.randn(4 * hidden_size, input_size))\n",
    "        self.weight_hh = nn.Parameter(torch.randn(4 * hidden_size, hidden_size))\n",
    "        self.bias = nn.Parameter(torch.randn(4 * hidden_size))\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.weight_ih)\n",
    "        nn.init.xavier_uniform_(self.weight_hh)\n",
    "        nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, input, hx):\n",
    "        h, c = hx\n",
    "        gates = F.linear(input, self.weight_ih, self.bias) + F.linear(h, self.weight_hh)\n",
    "        \n",
    "        z, i, f, o = gates.chunk(4, 1)\n",
    "        \n",
    "        z = torch.tanh(z)\n",
    "        i = torch.exp(i)  # Exponential input gate\n",
    "        f = torch.exp(f)  # Exponential forget gate\n",
    "        o = torch.sigmoid(o)\n",
    "        \n",
    "        c = f * c + i * z\n",
    "        h = o * torch.tanh(c)\n",
    "        \n",
    "        return h, c\n",
    "        \n",
    "\n",
    "class sLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout=0.0):\n",
    "        super(sLSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.layers = nn.ModuleList([sLSTMCell(input_size if i == 0 else hidden_size, hidden_size) \n",
    "                                     for i in range(num_layers)])  # multiple memory\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input_seq, hidden_state=None):\n",
    "        batch_size, seq_length, _ = input_seq.size()\n",
    "        \n",
    "        if hidden_state is None:\n",
    "            hidden_state = self.init_hidden(batch_size)\n",
    "        \n",
    "        outputs = []\n",
    "        for t in range(seq_length):\n",
    "            x = input_seq[:, t, :]\n",
    "            for layer_idx, layer in enumerate(self.layers):\n",
    "                h, c = hidden_state[layer_idx]\n",
    "                h, c = layer(x, (h, c))\n",
    "                hidden_state[layer_idx] = (h, c)\n",
    "                x = self.dropout_layer(h) if layer_idx < self.num_layers - 1 else h\n",
    "            outputs.append(x)\n",
    "        \n",
    "        return torch.stack(outputs, dim=1), hidden_state\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return [(torch.zeros(batch_size, self.hidden_size, device=self.layers[0].weight_ih.device),\n",
    "                 torch.zeros(batch_size, self.hidden_size, device=self.layers[0].weight_ih.device))\n",
    "                for _ in range(self.num_layers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d48c5002-baf6-460f-99ba-d6b3af0c07f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sLSTMBlock(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout=0.0):\n",
    "        super(sLSTMBlock, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.lstm = sLSTM(input_size, hidden_size, num_layers, dropout)\n",
    "        self.norm = nn.LayerNorm(hidden_size)\n",
    "        self.activation = nn.GELU()\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "        self.proj = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "    def forward(self, input_seq, hidden_state=None):\n",
    "        lstm_output, hidden_state = self.lstm(input_seq, hidden_state)\n",
    "        output = self.activation(lstm_output)\n",
    "        output = self.norm(output)\n",
    "        output = self.proj(output)\n",
    "        output = self.dropout_layer(output + input_seq)  # Residual connection\n",
    "        return output, hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7c48f9-f2f3-4aed-ac39-c9f7f35662b4",
   "metadata": {},
   "source": [
    "## AttensLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50994568-3a58-4eca-9fd9-bba719790e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttensLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size, num_layers, num_heads, num_blocks, seq_length, device, dropout=0.0):\n",
    "        super(AttensLSTM, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_heads = num_heads\n",
    "        self.num_blocks = num_blocks\n",
    "        self.seq_length = seq_length\n",
    "        self.device = device\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.encoder = Encoder(src_vocab_size=self.vocab_size, embed_size=self.embedding_size, num_layers=self.num_layers,\n",
    "                               heads=self.num_heads, device=self.device, forward_expansion=2, \n",
    "                               dropout=self.dropout, max_length=self.seq_length)\n",
    "                                \n",
    "        self.blocks = nn.ModuleList([\n",
    "            sLSTMBlock(embedding_size, hidden_size, num_layers, dropout)\n",
    "            for _ in range(num_blocks)\n",
    "        ])\n",
    "        self.output_layer = nn.Linear(embedding_size, vocab_size)\n",
    "\n",
    "    def forward(self, input_seq, hidden_states=None):\n",
    "        # embedded_seq = self.embedding(input_seq)\n",
    "        encoded_seq = self.encoder(input_seq, mask=None)\n",
    "        \n",
    "        if hidden_states is None:\n",
    "            hidden_states = [None] * self.num_blocks\n",
    "        \n",
    "        # output_seq = embedded_seq\n",
    "        output_seq = encoded_seq\n",
    "        for i, block in enumerate(self.blocks):\n",
    "            output_seq, hidden_states[i] = block(output_seq, hidden_states[i])\n",
    "        \n",
    "        output_seq = self.output_layer(output_seq)\n",
    "        return output_seq, hidden_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24add842-0e6f-497b-9840-b09b7d358eff",
   "metadata": {},
   "source": [
    "## Shape verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4712a890-9ad4-4f7b-9a2a-1ed567af3167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "vocab_size = 10000\n",
    "batch_size = 4\n",
    "seq_length = 10\n",
    "embedding_size = 256\n",
    "hidden_size = 512\n",
    "num_layers = 2\n",
    "num_heads = 4\n",
    "num_blocks = 3\n",
    "dropout = 0.1\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Generate random input sequence\n",
    "input_seq = torch.randint(0, vocab_size, (batch_size, seq_length)).to(device)\n",
    "\n",
    "model = AttensLSTM(vocab_size=vocab_size, embedding_size=embedding_size, hidden_size=hidden_size, num_layers=num_layers, num_heads=num_heads, \n",
    "                   num_blocks=num_blocks, seq_length=seq_length, device=device, dropout=dropout).to(device)\n",
    "\n",
    "output, hidden_state = model(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd8a45f2-c221-4c69-a802-4702935449c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 10000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faa0db1-239b-4e51-858b-38f1e2019810",
   "metadata": {},
   "source": [
    "## Regular task: even pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "572d4e7f-498e-4874-9173-7b079f784931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def even_pairs(\n",
    "    num_samples, vocab_size, # =2 for binary seq\n",
    "    seq_length, seed\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    input_seq = torch.tensor(rng.integers(vocab_size, size=[num_samples, seq_length]))\n",
    "    output_seq = torch.zeros(num_samples, seq_length)\n",
    "\n",
    "    for sample_idx in range(num_samples):\n",
    "        output_seq[sample_idx, -1] = int(input_seq[sample_idx, 0] == input_seq[sample_idx, -1])\n",
    "        \n",
    "    return input_seq, output_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aac8379c-742a-404b-aec6-3e993803c10c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 1, 0, 1, 1],\n",
       "         [1, 1, 0, 0, 0],\n",
       "         [1, 0, 0, 1, 0],\n",
       "         [1, 0, 1, 1, 1],\n",
       "         [0, 0, 1, 1, 1],\n",
       "         [1, 0, 0, 0, 1],\n",
       "         [1, 0, 1, 0, 1],\n",
       "         [1, 1, 1, 1, 0],\n",
       "         [1, 0, 1, 0, 1],\n",
       "         [0, 0, 1, 0, 0]]),\n",
       " tensor([[0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1.]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "vocab_size = 2\n",
    "num_samples = 10\n",
    "seq_length = 5\n",
    "\n",
    "even_pairs(num_samples=num_samples, vocab_size=vocab_size, seq_length=seq_length, seed=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dc2bfc1-b4ee-4077-a467-81aa00495c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "vocab_size = 2\n",
    "embedding_size = 128\n",
    "hidden_size = 256\n",
    "\n",
    "num_layers = 1\n",
    "num_blocks = 2\n",
    "\n",
    "num_samples = 300\n",
    "batch_size = 64\n",
    "seq_length = 20\n",
    "\n",
    "num_epochs = 20\n",
    "learning_rate = 0.0001\n",
    "clip_value = 1\n",
    "\n",
    "class even_pairsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, num_samples, vocab_size, seq_length):\n",
    "        self.input, self.target = even_pairs(num_samples=num_samples, vocab_size=vocab_size,\n",
    "                                             seq_length=seq_length, seed=31)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        input = self.input[idx]\n",
    "        target = self.target[idx]\n",
    "        return input, target\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AttensLSTM(vocab_size=vocab_size, embedding_size=embedding_size, hidden_size=hidden_size, num_layers=num_layers, num_heads=num_heads, \n",
    "                   num_blocks=num_blocks, seq_length=seq_length, device=device, dropout=dropout).to(device)\n",
    "\n",
    "def init_weights(m):\n",
    "    # print(m)\n",
    "    if type(m) in [nn.Linear, nn.Embedding]:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        if hasattr(m, 'bias') and m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "model.apply(init_weights)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_dataset = even_pairsDataset(num_samples, vocab_size, seq_length)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = even_pairsDataset(num_samples, vocab_size, seq_length)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bb4a73e-de28-446a-a52b-32a68cf6741e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, (input, target) in enumerate(train_loader):\n",
    "        input_seq = input.to(device)\n",
    "        target_seq = target.to(device)\n",
    "        output, _ = model(input_seq)\n",
    "        output = output.contiguous().view(-1, vocab_size)\n",
    "        target_seq = target_seq.contiguous().view(-1)\n",
    "        \n",
    "        loss = criterion(output, target_seq.long())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        #print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx+1}/{len(train_loader)}, Training Loss: {loss.item()}\")\n",
    "        \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Average Training Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "411003b6-c252-4cef-95f2-9b79878a1122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(epoch):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    gt_seq = []\n",
    "    pred_seq = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (input, target) in enumerate(test_loader):\n",
    "            input_seq = input.to(device)\n",
    "            target_seq = target.to(device)\n",
    "            output, _ = model(input_seq)\n",
    "            output = output.contiguous().view(-1, vocab_size)\n",
    "            target_seq = target_seq.contiguous().view(-1)\n",
    "            loss = criterion(output, target_seq.long())\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "            preds = torch.argmax(output, 1)\n",
    "            pred_seq.append(preds.cpu().data.numpy())\n",
    "            gt_seq.append(target_seq.cpu().data.numpy())\n",
    "\n",
    "            #print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx+1}/{len(train_loader)}, Validation Loss: {loss.item()}\")\n",
    "\n",
    "    val_loss = val_loss/len(test_loader)\n",
    "    gt_seq, pred_seq = np.concatenate(gt_seq), np.concatenate(pred_seq)\n",
    "    acc = np.sum(gt_seq==pred_seq)/len(pred_seq)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Average Validation Loss: {val_loss:.4f}, Accuracy: {acc:.4f}\")\n",
    "    # print('Epoch: {} \\tValidation Loss: {:.6f}, Accuracy: {:6f}'.format(epoch, val_loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eccc5015-789b-4269-bedd-53c2f5ba9c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Average Training Loss: 0.2233\n",
      "Epoch 1/20, Average Validation Loss: 0.2249, Accuracy: 0.9757\n",
      "\n",
      "Epoch 2/20, Average Training Loss: 0.1800\n",
      "Epoch 2/20, Average Validation Loss: 0.1311, Accuracy: 0.9757\n",
      "\n",
      "Epoch 3/20, Average Training Loss: 0.1425\n",
      "Epoch 3/20, Average Validation Loss: 0.0870, Accuracy: 0.9753\n",
      "\n",
      "Epoch 4/20, Average Training Loss: 0.1289\n",
      "Epoch 4/20, Average Validation Loss: 0.0902, Accuracy: 0.9757\n",
      "\n",
      "Epoch 5/20, Average Training Loss: 0.1027\n",
      "Epoch 5/20, Average Validation Loss: 0.0714, Accuracy: 0.9757\n",
      "\n",
      "Epoch 6/20, Average Training Loss: 0.0863\n",
      "Epoch 6/20, Average Validation Loss: 0.0390, Accuracy: 0.9803\n",
      "\n",
      "Epoch 7/20, Average Training Loss: 0.0776\n",
      "Epoch 7/20, Average Validation Loss: 0.0389, Accuracy: 0.9798\n",
      "\n",
      "Epoch 8/20, Average Training Loss: 0.0721\n",
      "Epoch 8/20, Average Validation Loss: 0.0398, Accuracy: 0.9788\n",
      "\n",
      "Epoch 9/20, Average Training Loss: 0.0667\n",
      "Epoch 9/20, Average Validation Loss: 0.0413, Accuracy: 0.9785\n",
      "\n",
      "Epoch 10/20, Average Training Loss: 0.0678\n",
      "Epoch 10/20, Average Validation Loss: 0.0397, Accuracy: 0.9797\n",
      "\n",
      "Epoch 11/20, Average Training Loss: 0.0676\n",
      "Epoch 11/20, Average Validation Loss: 0.0378, Accuracy: 0.9807\n",
      "\n",
      "Epoch 12/20, Average Training Loss: 0.0665\n",
      "Epoch 12/20, Average Validation Loss: 0.0342, Accuracy: 0.9827\n",
      "\n",
      "Epoch 13/20, Average Training Loss: 0.0560\n",
      "Epoch 13/20, Average Validation Loss: 0.0368, Accuracy: 0.9820\n",
      "\n",
      "Epoch 14/20, Average Training Loss: 0.0562\n",
      "Epoch 14/20, Average Validation Loss: 0.0347, Accuracy: 0.9827\n",
      "\n",
      "Epoch 15/20, Average Training Loss: 0.0548\n",
      "Epoch 15/20, Average Validation Loss: 0.0299, Accuracy: 0.9863\n",
      "\n",
      "Epoch 16/20, Average Training Loss: 0.0538\n",
      "Epoch 16/20, Average Validation Loss: 0.0261, Accuracy: 0.9892\n",
      "\n",
      "Epoch 17/20, Average Training Loss: 0.0546\n",
      "Epoch 17/20, Average Validation Loss: 0.0268, Accuracy: 0.9867\n",
      "\n",
      "Epoch 18/20, Average Training Loss: 0.0475\n",
      "Epoch 18/20, Average Validation Loss: 0.0298, Accuracy: 0.9842\n",
      "\n",
      "Epoch 19/20, Average Training Loss: 0.0481\n",
      "Epoch 19/20, Average Validation Loss: 0.0239, Accuracy: 0.9882\n",
      "\n",
      "Epoch 20/20, Average Training Loss: 0.0518\n",
      "Epoch 20/20, Average Validation Loss: 0.0289, Accuracy: 0.9828\n",
      "\n",
      "Training completed! Total time: 6.18 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    train(epoch)\n",
    "    val(epoch)\n",
    "    print()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training completed! Total time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5555616-3491-4767-ad6c-9ac9f3d01ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
